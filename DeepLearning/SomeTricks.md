# 炼丹心得和歪理 in Mess

## Data preprocessing period

+ 数据质量直接影响模型精度。</br>模型精度在开始阶段可以通过调整模型结构来提升（e.g. 添加注意力，添加DCN，增强Backbone），但后期如果需要继续提升模型精度，或增强泛化性，就需要补充数据集，尤其是badcas。
+ 测试集很重要，测试集一般不是从训练集中切分出来的，从训练集中切分出来的是验证集。</br>验证集一般用于判断这个模型有没有过拟合、有没有训练走火入魔啦.验证集往往并不能代表模型实际的水平。</br>因此项目最好有测试集，而且测试集和模型采集批次不同，测试集比较接近实际水平的评价标准。</br>如果没有测试集，可以看训练集的loss大概确定一下。一般来说，只要不是demo级别的场景，模型不会轻易过拟合。如果训练集有很重的图像增强策略，导致每一个epoch可能图像分布都不一样，因此可以选取训练得到的最后一个模型。
+ 在有监督学习中，数据标注往往是人工完成的，因此标注/标签错误经常发生。</br>事实上，深度学习算法对随机错误的容忍度很高，少量错误样本对训练结果几乎没有影响。但如果数据集中有系统性的批量错误，那问题就比较严重，模型会学习这种错误的规律。因此数据集往往需要一定程度的手动修正。
+ 纠正错标数据集时的points:
  + 由于训练集、验证集和测试集往往来自同一个分布，因此纠正数据的过程应该在三者之间同步进行。
  + 不仅要纠正模型输出错误的样本中的错标样本，还要考虑标注错误却输出正确的样本。
+ 如果项目有来自不同分布的数据，那么需要结合项目背景对数据集进行划分，尽可能让验证集/测试集只包含我们期待的理想情况下的分布中的数据，即使这样会使得结果不那么好看。（特殊情况除外（笑））

## Training period

## Validation period

+ loss 和准确率不一定是正相关的。</br>loss通常都会有波动，loss 低了不一定代表模型的mAP高；loss 变高也不一定代表模型的精度变差。
+ 当验证集出现 loss 变高，精度也提高的情况时，可以通过在网络的每一层添加 Normalization 来一定程度上缓解这种现象。

## Testing period

+ 当模型遇到 badcase 的时候，简单粗暴地增加模型的 batch size 效果可能并不好。</br>badcase 通常和项目背景强相关，这种情况下最好的方法是收集并进行 badcase 分析。可能会有使用该模型的人提供 badcase，但这种效率比较低，取决于数据提供者的心情 or 紧急程度；也可以直接捞一大批模型使用场景的 query 并使用当前模型做检测，收集相应类别置信度比较低的case，然后挑选出来。
+ 测试时结果不好，除了模型欠拟合/过拟合以外，还有一种可能是，测试集数据和训练集、验证集不匹配。</br>为区分到底是哪种原因造成的，可以将部分测试集的分布调整至和训练集一致，替换原本的验证集。这种数据集被称作训练开发集（training-dev set）。通过比较模型在训练集和训练开发集上的准确度，从而单独评估模型的方差，拆分欠拟合/过拟合和数据不匹配问题。
  